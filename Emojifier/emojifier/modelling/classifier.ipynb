{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "from gensim.models import Word2Vec\n",
    "import torch\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets\n",
      "['Y’all can’t get tender when I don’t respond 😂\\n', 'dawg this game finna blow me 😂\\n', '😂 😂 😂\\n']\n",
      "Chosen emojis\n",
      "['😂', '😍', '😭', '😊', '💕', '😒', '😉', '👌', '👍', '🙏', '👀', '🔥', '💯', '👏', '💪']\n"
     ]
    }
   ],
   "source": [
    "# getting the twitter comments\n",
    "DATA_PATH = '../data/twitter-data-cleaned.txt'\n",
    "with open(DATA_PATH, 'r',  encoding=\"utf-8\") as f:\n",
    "    data = f.readlines()\n",
    "print('Tweets')\n",
    "print(data[:3])\n",
    "\n",
    "# getting our chosen emojis\n",
    "SELECTED_EMOJIS_PATH = '../data/best-emojis.json'\n",
    "with open(SELECTED_EMOJIS_PATH, 'r') as f:\n",
    "    EMOJIS = json.load(f)\n",
    "EMOJI_CHARS = [e['char'] for e in EMOJIS]\n",
    "print('Chosen emojis')\n",
    "print(EMOJI_CHARS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😂\n",
      "192\n",
      "[['i', 'don’t', 'respond'], ['finna', 'blow', 'me'], ['we', 'in', 'trouble']]\n",
      "😍\n",
      "153\n",
      "[['scramble', 'city', 'ksw55'], ['just', 'wow', 'amazing'], ['the', 'second', 'pic']]\n",
      "😭\n",
      "164\n",
      "[['miss', 'paris', 'tho'], ['they’re', 'so', 'cuteee'], ['they’re', 'so', 'cuteee']]\n",
      "😊\n",
      "114\n",
      "[['hi', 'can', 'u'], ['all', 'of', 'them'], ['harming', 'other', 'people']]\n",
      "💕\n",
      "133\n",
      "[['olivia', 'newton', 'john'], ['amp', 'baby', 'gia'], ['do', 'the', 'job']]\n",
      "😒\n",
      "98\n",
      "[['starters', 'on', 'defense'], ['talk', 'to', 'em'], ['know', 'the', 'feeling']]\n",
      "😉\n",
      "109\n",
      "[['gets', 'literally', '25000+'], ['amp', 'gurlish', 'side'], ['you’re', 'right']]\n",
      "👌\n",
      "110\n",
      "[['make', 'people', 'laugh'], ['thanks'], ['war', 'here', 'soon']]\n",
      "👍\n",
      "123\n",
      "[['it', 'up', 'brother'], ['thanks', 'venting', 'to'], ['you’re', 'very', 'welcome']]\n",
      "🙏\n",
      "148\n",
      "[['the', 'shirt', 'please'], ['to', 'see', 'again'], ['my', 'dear', 'friend']]\n",
      "👀\n",
      "123\n",
      "[['when', 'life', 'gets'], ['rt', 'that', 'tweet'], ['one', 'is', 'from']]\n",
      "🔥\n",
      "190\n",
      "[['install', 'golden', 'match'], ['this', 'gorgeous', 'look'], ['it’s', 'lit', 'enjoy']]\n",
      "💯\n",
      "114\n",
      "[['️'], ['art', 'action', 'drama'], ['hall', 'of', 'fame']]\n",
      "👏\n",
      "207\n",
      "[['would', 'be', 'awesome'], ['hall', 'of', 'fame'], ['epic', 'classic']]\n",
      "💪\n",
      "124\n",
      "[['love', 'of', 'all'], ['love', 'of', 'all'], ['bathampb…']]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing the data\n",
    "from parsing import Tokenizer, TokenType, Token\n",
    "tokenizer = Tokenizer(EMOJI_CHARS)\n",
    "# take 3 previous words as context for the emoji\n",
    "context = {e:[] for e in EMOJI_CHARS}\n",
    "for tweet in data:\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    for i,token in enumerate(tokens):\n",
    "        if token.token_type == TokenType.EMOJIS:\n",
    "            closest = tokenizer.findClosest3Words(tokens, i)\n",
    "            if closest:\n",
    "                context[token.raw].append(closest)\n",
    "\n",
    "for e, words in context.items():\n",
    "    print(e)\n",
    "    print(len(words))\n",
    "    print(words[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
